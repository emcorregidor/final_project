---
title             : "*Emotionality in a second language: It's a matter of time* (Opitz & Degner, 2012): an adaptation"
shorttitle        : "Data Science for Linguists: Final Project"

author: 
  - name          : "Eva María Corregidor Luna"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "15 Seminary Place, 5th Flr, Office 5187"
    email         : "eva.corregidor@rutgers.edu"

affiliation:
  - id            : "1"
    institution   : "Department of Spanish and Portuguese. Rutgers University"

bibliography      : "r-references.bib"

floatsintext      : no
linenumbers       : no
draft             : no
mask              : no

figurelist        : no
tablelist         : no
footnotelist      : no

classoption       : "man"
output            : papaja::apa6_word
---

```{r setup, include = FALSE}
library("papaja")
r_refs("r-references.bib")
source("../scripts/libs.R")
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

# Methods
## Participants
150 English–Spanish bilinguals (75 women), aged 25–35 years, were recruited among the administrative personnel from Rutgers University to participate in the study. Two participants were excluded from the analysis because of excessive artifacts. All were right-handed, had normal or corrected-to-normal vision, and reported no history of neurological or language disorders.

Participants were late L2 learners and started to learn Spanish at age 12 as part of their education. By the time of the study, they were highly proficient in Spanish (add proficiency test), and reported a mean of self-rated frequency of weekly L2 use of 65%, mostly in work-related settings. All participants had spent at least one long stay (>6 months) in a L2 country.

## Materials

## Language History Questionnaire
The Language History questionnaire was used to obtain information about the bilingual profile, L2 acquisition, L2 use, and L2 frequency. It contained 7 multiple-choice questions, 8 questions with numerical scales, and 5 open questions (total of 20 questions).

## Lexical Monitoring Task
Stimuli were obtained from an English words database (Kuperman & Imbault, 2020) where words were rated by participants based on valence and arousal. From the database, the 50 words with the highest valence level were chosen to be the emotional words. Similarly, the 50 words with the lowest valance level were chosen to be the non-emotional words. All words were nouns and were matched in word length, frequency of use. For the pseudo-words, 50 words were created using Artificial Intelligence (AI).

The Lexical Monitoring Task (LMT) is an adaptation of the lexical decision task (Opitz & Degner, 2012). In the LMT, participants look at a monitor screen, see a word, and decide whether it is a real word or not (Yes/No decision). The task was divided into five rounds, each with 30 trials (10 emotion words, 10 non-emotion words, 10 pseudo-words).

## Statistical analysis
Data from the Language History Questionnaire and the Lexical Monitoring Task were analyzed. Data were analyzed using R (2021). All data and scripts follow open-science practices and are available at the [GitHub repository of the project](https://emcorregidor.github.io/final_project/).

For the accuracy model, a generalized linear mixed-effects model with a binomial linking function (as implemented in the lme4 package 1.1-37 in R 2024.12.0+467) was used. The accuracy model included *accuracy* (right vs. wrong) as the dependent variable, and *task language* (*L1* vs. *L2*) as a fixed factor or predictor. A "right" response was coded as "0" and a "wrong" response was coded as "1".

For the latency model, a generalized linear mixed-effects model (as implemented in the lme4 package 1.1-37 in R 2024.12.0+467) was used. The latency model included *latency* (190-490 ms) as the dependent variable, and *task language* (*L1* vs. *L2*) as a fixed factor or predictor.

Both models included random slopes for participants and item (Baayen et al., 2008). The models also included a *word type*  interaction. P-values with alpha set at 0.05 and confidence intervals of parameter estimates for both models are reported to provide an assessment of effect sizes. R- squared is reported for each model as an indication of goodness of fit (Nakagawa and Schielzeth, 2013).

# Results

The accuracy model showed a good fit, with most of the variance explained by the fixed predictors rather than the random effects (marginal R2 = 0.1735; conditional R2 = 0.1787). For random effects, the accuracy model shows variability for participants (variance = 2.091e-02). This confirms that participants vary in their performance and allows the model to assign a different baseline for each one of them. In contrast, there is no variability for item (variance = 1.148e-09). This indicates almost no variance per item, so allowing each item to have its own slope might be unnecessary.

In terms of fixed effects, the accuracy model indicates that, when switching to the L2, accuracy decreases (estimate = -1.8199, CI = –1.91, –1.73, p < 2e-16). Word type does not have a significant effect (estimate = -0.0147, CI = -0.1210, 0.0915, p = 0.786). However, the model reveals a significant interaction between L2 and word type (estimate = 0.3362, CI = 0.2107, 0.4618, p = 1.53e-07). More concretely, when using the L2, non emotional words are performed better. As a consequence, emotional words in the L2 are processed less accurately.

```{r}
#| out-width: "75%"
#| max-width: "100%"
#| dpi: 400
knitr::include_graphics(here::here("scripts", "plots", "plot_accuracy.png"))
```

The latency model showed a good fit, with most of the variance explained by the fixed predictors rather than the random effects (marginal R2 = 0.7458; conditional R2 = 0.7520). For random effects, the latency model shows a great variability for participants (variance = 16.01). This confirms that participants vary in their performance and allows the model to assign a different baseline for each one of them. In contrast, there is no variability for item (variance = 0). No variance per item indicates that allowing each item to have its own slope does not provide any meaningful information about the model.

In terms of fixed effects, the latency model indicates that, when switching to the L2, latency increases (estimate = 95.0539, CI = 94.2422, 95.8656). Word type has a latency effect in both languages. More specifically, non emotional words are processed faster both in the L1 (estimate = -0.1250, CI = -0.9366, 0.6867), and the L2 (estimate = -15.5651, CI = -16.7130, -14.4172). These results reveal an interaction between language and word type. More concretely, when using the L2, non emotional words are processed faster than emotional words. The same is true for the L1, but effects are much smaller (15.5651 > 0.1250).

```{r}
#| out-width: "75%"
#| max-width: "100%"
#| dpi: 400
knitr::include_graphics(here::here("scripts", "plots", "plot_latency.png"))
```

\newpage

# References

Baayen, R. H., Davidson, D. J., & Bates, D. M. (2008). Mixed-effects modeling with crossed random effects for subjects and items. Journal of Memory and Language, 59(4), 390–412. https://doi.org/10.1016/j.jml.2007.12.005

Kuperman, V., & Imbault, C. (2020, February 27). How are words felt in a 2nd language: Norms for 2,668 English words for valence and arousal by non-native speakers. OSF. https://osf.io/nr9wj

Nakagawa, S., & Schielzeth, H. (2013). A general and simple method for obtaining R2 from generalized linear mixed-effects models. Methods in Ecology and Evolution, 4(2), 133-142. https://doi.org/10.1111/j.2041-210x.2012.00261.x

Opitz, B., & Degner, J. (2012). Emotionality in a second language: it's a matter of time. Neuropsychologia, 50(8), 1961–1967. https://doi.org/10.1016/j.neuropsychologia.2012.04.021

R Core Team (2021). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. https://www.R-project.org/.

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
